{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "global gama\n",
    "states = 100\n",
    "actions = 4\n",
    "reward = -0.01\n",
    "gama = 0\n",
    "world = np.zeros((states, actions))\n",
    "\n",
    "pits = []\n",
    "j = 0\n",
    "while True:\n",
    "    p = np.random.randint(1,99)\n",
    "    if p not in pits:\n",
    "        pits.append(p)\n",
    "        j+=1\n",
    "        if j > 10:\n",
    "            break\n",
    "\n",
    "wins = [0,99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "x = tf.placeholder(tf.float32, shape=[None, states], name='input_states')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, actions], name='correct_answer')\n",
    "W = tf.Variable(tf.zeros([states ,actions]), name='weights')\n",
    "b = tf.Variable(tf.zeros([actions]), name='bias')\n",
    "\n",
    "# predicted action\n",
    "y = tf.matmul(x,W) + b\n",
    "y_soft = tf.nn.softmax(y)\n",
    "\n",
    "# cross_antropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y^2), reduction_indices=[1]))\n",
    "\n",
    "loss = tf.reduce_mean(tf.squared_difference(y, y_))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_next_state(state, gama):\n",
    "    # act greedy with random\n",
    "    coin = np.random.randint(500 + gama)\n",
    "    a = get_best_action_from_nn(state)\n",
    "    if coin < 400:\n",
    "        random_actions = []\n",
    "        for x in range(actions):\n",
    "            if x !=a:\n",
    "                random_actions.append(x)\n",
    "        \n",
    "        i = np.random.randint(len(random_actions))\n",
    "        a = random_actions[i-1]\n",
    "    s = get_next_valid_state(state, a)\n",
    "\n",
    "    return s, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LEFT = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "UP = 3\n",
    "\n",
    "def get_possible_actions(state):\n",
    "    x = int(state % np.sqrt(states))\n",
    "    y = int(state // np.sqrt(states))\n",
    "    actions=[]\n",
    "    if x > 0:\n",
    "        actions.append(LEFT)\n",
    "        if x < (np.sqrt(states) - 1):\n",
    "            actions.append(RIGHT)        \n",
    "    elif x < (np.sqrt(states) - 1):\n",
    "            actions.append(RIGHT)\n",
    "\n",
    "    if y > 0:\n",
    "        actions.append(DOWN)\n",
    "        if y < (np.sqrt(states) - 1):\n",
    "            actions.append(UP)\n",
    "    elif y < (np.sqrt(states) - 1):\n",
    "            actions.append(UP)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_next_valid_state(state, action):\n",
    "    x = int(state % np.sqrt(states))\n",
    "    y = int(state // np.sqrt(states))   \n",
    "    if x > 0 and action == LEFT:\n",
    "        return state - 1\n",
    "    if x < 9 and action == RIGHT:\n",
    "        return state + 1\n",
    "    if y > 0 and action == DOWN:\n",
    "        return state - int(np.sqrt(states)) \n",
    "    if y < 9 and action == UP:\n",
    "        return state + int(np.sqrt(states))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_current_reward(state):\n",
    "    if state in wins:\n",
    "        return 1000\n",
    "    if state in pits:\n",
    "        return -1000\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_state_as_array(state):\n",
    "    s = np.zeros(states, dtype=np.float32)\n",
    "    s[state] = 1.0\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_reward_from_nn(state, a):\n",
    "    s = get_state_as_array(state)\n",
    "    b = sess.run(y, feed_dict={x: [s]})\n",
    "    return b[0,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_best_action_from_nn(state):\n",
    "    s = get_state_as_array(state)\n",
    "    a = sess.run(tf.arg_max(y,1), feed_dict={x: [s]})\n",
    "    return a[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_max_reward_from_nn(state):\n",
    "    s = get_state_as_array(state)\n",
    "    m = sess.run(tf.reduce_max(y,1), feed_dict={x: [s]})\n",
    "    return m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_all_rewards(state):\n",
    "    s = get_state_as_array(state)\n",
    "    b = sess.run(y, feed_dict={x: [s]})\n",
    "    return b[0].tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(state, rewards):\n",
    "    s = get_state_as_array(state)\n",
    "    for i in range(5):\n",
    "        sess.run(train_step, feed_dict={x:[s], y_:[rewards]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_first_state():\n",
    "    found = False\n",
    "    while not found:\n",
    "        state = np.random.randint(states)\n",
    "        if state not in wins and state not in pits:\n",
    "            return state\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_rewards(state):\n",
    "    possible_actions = get_possible_actions(state)\n",
    "    all_rewards = get_all_rewards(state)\n",
    "\n",
    "    for action in range(actions):\n",
    "        if action in possible_actions:\n",
    "            next_state = get_next_valid_state(state, action)\n",
    "            reward = get_max_reward_from_nn(next_state)\n",
    "            all_rewards[action] = reward - 0.1\n",
    "        else:\n",
    "            all_rewards[action] = 0\n",
    "#     all_rewards = softmax(all_rewards)\n",
    "    return all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = get_first_state()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = state\n",
    "while True:\n",
    "    state, la = get_next_state(state, 100)\n",
    "    if state != ls:\n",
    "        break\n",
    "\n",
    "\n",
    "cr = get_current_reward(state)\n",
    "\n",
    "pa = get_possible_actions(ls)\n",
    "\n",
    "rr = []\n",
    "for i in range(actions):\n",
    "    if i in pa:\n",
    "        s1 = get_next_valid_state(ls, i)\n",
    "        r1 = get_max_reward_from_nn(s1)\n",
    "        rr.append(r1 - 1)\n",
    "    else:\n",
    "        rr.append(-20)\n",
    "if cr !=0:\n",
    "    rr[la] = cr\n",
    "\n",
    "s = get_state_as_array(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    sess.run(train_step, feed_dict={x:[s], y_:[rr]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 80, 1, [-20, -1.984375, -1.4921875, -1.4921875])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, ls, la, rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-19.999980926513672,\n",
       " -1.9843735694885254,\n",
       " -1.4921865463256836,\n",
       " -1.4921865463256836]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_rewards(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sort(pits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "board = [\"\" for i in range(100)]\n",
    "\n",
    "for i in range(states):\n",
    "        a = get_best_action_from_nn(i)\n",
    "        if a == LEFT:\n",
    "            board[i] = '<'\n",
    "        elif a == RIGHT:\n",
    "            board[i] = '>'\n",
    "        elif a == DOWN:\n",
    "            board[i] = '^'\n",
    "        else:\n",
    "            board[i] = 'V'\n",
    "\n",
    "for p in pits:\n",
    "    board[p] = 'O'\n",
    "board[99] = 'X'\n",
    "board[0] = 'X'\n",
    "board = np.reshape(board, (10,10))\n",
    "\n",
    "\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ww = sess.run(W, feed_dict={x:[s], y_:[rr]})\n",
    "bb = sess.run(b, feed_dict={x:[s], y_:[rr]})\n",
    "ww, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for k in range(1000):\n",
    "\n",
    "    ls = state\n",
    "    while True:\n",
    "        state, la = get_next_state(state, 100)\n",
    "        if state != ls:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    cr = get_current_reward(state)\n",
    "\n",
    "    pa = get_possible_actions(ls)\n",
    "\n",
    "    rr = []\n",
    "    for i in range(actions):\n",
    "        if i in pa:\n",
    "            s1 = get_next_valid_state(ls, i)\n",
    "            r1 = get_max_reward_from_nn(s1)\n",
    "            rr.append(r1 - 1)\n",
    "        else:\n",
    "            rr.append(-20)\n",
    "    if cr !=0:\n",
    "        rr[la] = cr\n",
    "        \n",
    "    s = get_state_as_array(ls)\n",
    "    for i in range(5):\n",
    "        sess.run(train_step, feed_dict={x:[s], y_:[rr]})        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
